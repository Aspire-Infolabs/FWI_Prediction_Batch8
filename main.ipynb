{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILESTONE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"FWI Dataset.csv\")\n",
    "print(df)\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Region' in df.columns:\n",
    "    print(\"Encoding Region column...\")\n",
    "    df['Region'] = df['Region'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Original columns:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values before cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows containing missing values:\")\n",
    "print(df[df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "print(\"Column names after stripping spaces:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cleaning string columns\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].astype(str).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fixing corrupted numeric entries\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.replace(\"  \", \" \")\n",
    "    if df[col].dtype == 'object' and df[col].str.contains(\" \").any():\n",
    "        df[col] = df[col].str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['Temperature','RH','Ws','Rain','FFMC','DMC','DC','ISI','BUI','FWI']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filling missing values with mode\")\n",
    "df['Region'] = df['Region'].fillna(df['Region'].mode()[0])\n",
    "df['Classes'] = df['Classes'].fillna(df['Classes'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Encoding categorical columns\")\n",
    "le_region = LabelEncoder()\n",
    "df['Region_encoded'] = le_region.fit_transform(df['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_class = LabelEncoder()\n",
    "df['Classes_encoded'] = le_class.fit_transform(df['Classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final dataset shape:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label encoding non-numeric columns\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in df_encoded.columns:\n",
    "    if df_encoded[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(\"Selecting all numeric columns (including encoded)\")\n",
    "numeric_df = df_encoded.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "print(\"Plotting correlation heatmap for all numeric features\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting histograms for all numeric columns\")\n",
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "numeric_df.hist(figsize=(15, 12), bins=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting correlation heatmap\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting density distribution plots (single frame)\")\n",
    "\n",
    "cols = numeric_df.columns\n",
    "n_cols = 3                       \n",
    "n_rows = int(np.ceil(len(cols) / n_cols))\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "\n",
    "for i, col in enumerate(cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.kdeplot(numeric_df[col], fill=True)\n",
    "    plt.title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Plotting boxplots for outlier detection (single frame)\")\n",
    "\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    df = pd.read_csv(\"FWI Cleaned.csv\")\n",
    "\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "cols = numeric_df.columns\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(cols) / n_cols))\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "\n",
    "for i, col in enumerate(cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.boxplot(x=numeric_df[col])\n",
    "    plt.title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing outlier treatment using IQR method\")\n",
    "\n",
    "for col in numeric_df.columns:\n",
    "    Q1 = numeric_df[col].quantile(0.25)\n",
    "    Q3 = numeric_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df[col] = df[col].clip(lower, upper)\n",
    "\n",
    "print(\"Outlier treatment completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking feature consistency\")\n",
    "print(df.isnull().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Plotting scatterplots for feature relationships\")\n",
    "\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    df = pd.read_csv(\"FWI Cleaned.csv\")\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(x=df['Temperature'], y=df['FWI'])\n",
    "plt.title(\"Temperature vs FWI\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(x=df['Ws'], y=df['FWI'])\n",
    "plt.title(\"Wind Speed (Ws) vs FWI\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(x=df['RH'], y=df['FWI'])\n",
    "plt.title(\"Relative Humidity (RH) vs FWI\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Head and shape of final cleaned dataset:\")\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"FWI Cleaned.csv\", index=False)\n",
    "print(\"Saved cleaned_fwi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILESTONE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FWI Cleaned.csv\")\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"FWI\"])\n",
    "\n",
    "print(\"After removing missing FWI values:\")\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"FWI\"\n",
    "\n",
    "features = [\n",
    "    \"Temperature\", \"RH\", \"Ws\", \"Rain\",\n",
    "    \"FFMC\", \"DMC\", \"DC\", \"ISI\", \"BUI\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "print(\"Selected Features:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"scaler.pkl saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"R2 Score\": r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=\"R2 Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=ridge,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"r2\"\n",
    ")\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Alpha:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated R2 Score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge = grid.best_estimator_\n",
    "\n",
    "y_pred = best_ridge.predict(X_test_scaled)\n",
    "\n",
    "print(\"Final Ridge Regression Performance:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred))\n",
    ")\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ridge.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_ridge, f)\n",
    "\n",
    "print(\"ridge.pkl saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Ridge Regression was selected as the final model because it \"\n",
    "    \"handles multicollinearity among correlated weather features \"\n",
    "    \"and demonstrated better generalization performance during \"\n",
    "    \"cross-validation.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = {\n",
    "    \"Model\": \"Ridge Regression\",\n",
    "    \"Best Alpha\": grid.best_params_[\"alpha\"],\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open(\"ridge.pkl\", \"rb\") as f:\n",
    "    ridge_model = pickle.load(f)\n",
    "\n",
    "sample = X_test.iloc[[0]]\n",
    "sample_scaled = scaler.transform(sample)\n",
    "prediction = ridge_model.predict(sample_scaled)\n",
    "\n",
    "print(scaler)\n",
    "print(ridge_model)\n",
    "\n",
    "print(\"Predicted FWI:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILESTONE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open(\"ridge.pkl\", \"rb\") as f:\n",
    "    ridge_model = pickle.load(f)\n",
    "\n",
    "print(\"Scaler and Ridge model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FWI Cleaned.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"FWI\"])\n",
    "\n",
    "print(\"Dataset loaded for evaluation\")\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"Temperature\", \"RH\", \"Ws\", \"Rain\",\n",
    "    \"FFMC\", \"DMC\", \"DC\", \"ISI\", \"BUI\"\n",
    "]\n",
    "\n",
    "target = \"FWI\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "print(\"Features and target defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train-test split completed\")\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "print(\"Training data scaled using saved scaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = ridge_model.predict(X_train_scaled)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "print(\"Training R2 Score:\", train_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r2 = r2_score(y_test, y_pred)\n",
    "print(\"Testing R2 Score:\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Test data scaled using saved scaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Predictions generated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(\"MAE :\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2  :\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "print(\"Residual analysis completed\")\n",
    "print(\"Residual mean:\", residuals.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual FWI\")\n",
    "plt.ylabel(\"Predicted FWI\")\n",
    "plt.title(\"Actual vs Predicted FWI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted FWI\")\n",
    "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
    "plt.title(\"Residuals vs Predicted FWI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Ridge alpha used:\", ridge_model.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"MAE\", \"RMSE\", \"R2 Score\"],\n",
    "    \"Value\": [mae, rmse, r2]\n",
    "})\n",
    "\n",
    "evaluation_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The Ridge Regression model demonstrates strong generalization \"\n",
    "    \"on unseen data. Residuals are centered around zero, indicating \"\n",
    "    \"unbiased predictions. Hyperparameter tuning improved performance \"\n",
    "    \"by controlling multicollinearity among weather features.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
